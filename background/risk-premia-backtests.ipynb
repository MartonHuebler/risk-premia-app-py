{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Premia Strategy Backtests\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Write file of 3-asset RP strategy returns, scaled to annualised volatility of 10%. (Rebalanced back to target vol every volLookback days)\n",
    "\n",
    "Set the end date below. Other parameters are:\n",
    "- initEq = 10000\n",
    "- perShareComm = 0.005\n",
    "- minCommPerOrder = 1\n",
    "- rebalFrequency = 1 (rebalance frequency in months)\n",
    "- capFrequency = 1 (frequency to capitalise profits. 0 is \"don't capitalise\")\n",
    "- assetVolTarget = 0.05\n",
    "- volLookback = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_end_date = \"2020-11-04\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pyreadr\nfrom pathlib import Path\nimport pickle\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n\n# Load prices from RData file\ndata_path = Path('..') / 'data' / 'prices.RData'\nresult = pyreadr.read_r(str(data_path))\nprices = result['us_etf_prices']\n\n# Convert date and sort\nprices['date'] = pd.to_datetime(prices['date'])\nprices = prices.sort_values('date').reset_index(drop=True)\n\nprint(f\"Loaded {len(prices)} rows of price data\")\nprices.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cumulative Returns to Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns from adjusted close\n",
    "plot_data = prices.copy()\n",
    "plot_data = plot_data.sort_values(['ticker', 'date'])\n",
    "plot_data['returns'] = plot_data.groupby('ticker')['closeadjusted'].pct_change()\n",
    "plot_data = plot_data.dropna(subset=['returns'])\n",
    "plot_data['cumreturns'] = plot_data.groupby('ticker')['returns'].apply(\n",
    "    lambda x: (1 + x).cumprod()\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ticker in plot_data['ticker'].unique():\n",
    "    ticker_data = plot_data[plot_data['ticker'] == ticker]\n",
    "    plt.plot(ticker_data['date'], ticker_data['cumreturns'], label=ticker)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.title('Cumulative Returns (Adjusted Prices)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest Setup\n",
    "\n",
    "Calculate monthly prices and start/end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get month-end dates\n",
    "prices_with_month = prices.copy()\n",
    "prices_with_month['year'] = prices_with_month['date'].dt.year\n",
    "prices_with_month['month'] = prices_with_month['date'].dt.month\n",
    "\n",
    "monthends = prices_with_month.groupby(['year', 'month'])['date'].max().reset_index()\n",
    "\n",
    "# Get monthly prices (use closeadjusted)\n",
    "monthlyprices = prices.merge(monthends, on='date')[['ticker', 'date', 'closeadjusted']]\n",
    "monthlyprices = monthlyprices.rename(columns={'closeadjusted': 'close'})\n",
    "\n",
    "# Set dates\n",
    "startDate = monthlyprices['date'].min()\n",
    "endDate = pd.to_datetime(backtest_end_date)\n",
    "initDate = startDate - pd.Timedelta(days=1)\n",
    "\n",
    "print(f\"Start Date: {startDate}\")\n",
    "print(f\"End Date: {endDate}\")\n",
    "print(f\"Number of monthly periods: {len(monthlyprices['date'].unique())}\")\n",
    "monthlyprices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 1: Equal Initial Weight Buy and Hold\n",
    "\n",
    "Here are the inputs for this strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initEq = 10000  # Initial equity ($1000 to $1 million)\n",
    "perShareComm = 0.005  # Per-share commission (0.001 to 0.02)\n",
    "minCommPerOrder = 1  # Minimum commission per order (0 to 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy assumes rebalFrequency = capFrequency = 0 (no rebalancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate initial shares - equal dollar weight\n",
    "initial_prices = monthlyprices[monthlyprices['date'] == startDate].copy()\n",
    "shares = initial_prices.copy()\n",
    "shares['shares'] = np.floor((initEq / 3) / shares['close']).astype(int)\n",
    "shares = shares[['ticker', 'shares']]\n",
    "\n",
    "# Merge shares with all prices\n",
    "ew_norebal = monthlyprices.merge(shares, on='ticker')\n",
    "ew_norebal['exposure'] = ew_norebal['shares'] * ew_norebal['close']\n",
    "\n",
    "# Calculate trades\n",
    "ew_norebal = ew_norebal.sort_values(['ticker', 'date'])\n",
    "ew_norebal['trades'] = ew_norebal.groupby('ticker')['shares'].diff().fillna(ew_norebal['shares'])\n",
    "ew_norebal['tradevalue'] = ew_norebal['trades'] * ew_norebal['close']\n",
    "\n",
    "# Calculate commissions\n",
    "ew_norebal['commission'] = np.abs(ew_norebal['trades']) * perShareComm\n",
    "ew_norebal.loc[ew_norebal['commission'] < minCommPerOrder, 'commission'] = minCommPerOrder\n",
    "ew_norebal.loc[ew_norebal['trades'] == 0, 'commission'] = 0\n",
    "\n",
    "# Calculate initial cash balance\n",
    "initial_investment = ew_norebal[ew_norebal['date'] == startDate]\n",
    "initcashbal = initEq - initial_investment['exposure'].sum() - initial_investment['commission'].sum()\n",
    "\n",
    "# Create cash rows\n",
    "cash_rows = []\n",
    "for date in ew_norebal['date'].unique():\n",
    "    if date == startDate:\n",
    "        tradevalue = initcashbal - initEq\n",
    "    else:\n",
    "        tradevalue = 0\n",
    "    \n",
    "    cash_rows.append({\n",
    "        'ticker': 'Cash',\n",
    "        'date': date,\n",
    "        'close': 0,\n",
    "        'shares': 0,\n",
    "        'exposure': initcashbal,\n",
    "        'trades': 0,\n",
    "        'tradevalue': tradevalue,\n",
    "        'commission': 0\n",
    "    })\n",
    "\n",
    "cash_df = pd.DataFrame(cash_rows)\n",
    "ew_norebal = pd.concat([ew_norebal, cash_df], ignore_index=True)\n",
    "ew_norebal = ew_norebal.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Buy and hold backtest created with {len(ew_norebal)} rows\")\n",
    "ew_norebal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart\n",
    "pivot_data = ew_norebal.pivot(index='date', columns='ticker', values='exposure')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(pivot_data.index, pivot_data.T, labels=pivot_data.columns, alpha=0.8)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Exposure ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Equal Weight, No Rebalancing')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trades chart\n",
    "trades_data = ew_norebal[ew_norebal['ticker'] != 'Cash']\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "tickers = sorted(trades_data['ticker'].unique())\n",
    "width = 20  # bar width in days\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_trades = trades_data[trades_data['ticker'] == ticker]\n",
    "    offset = (i - len(tickers)/2) * width\n",
    "    ax.bar(ticker_trades['date'] + pd.Timedelta(days=offset), \n",
    "           ticker_trades['tradevalue'], \n",
    "           width=width, \n",
    "           label=ticker)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Trade Value ($)')\n",
    "ax.set_title('3 ETF USD Risk Premia - Trades')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Commission chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_comm = ew_norebal.pivot(index='date', columns='ticker', values='commission')\n",
    "pivot_comm.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Commission ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Commission ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Commission as percentage of exposure\n",
    "comm_pct = ew_norebal.copy()\n",
    "comm_pct['commissionpct'] = comm_pct['commission'] / comm_pct['exposure'].replace(0, np.nan)\n",
    "comm_pct = comm_pct[comm_pct['ticker'] != 'Cash']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_data = comm_pct[comm_pct['ticker'] == ticker]\n",
    "    offset = (i - len(tickers)/2) * width\n",
    "    ax.bar(ticker_data['date'] + pd.Timedelta(days=offset), \n",
    "           ticker_data['commissionpct'], \n",
    "           width=width, \n",
    "           label=ticker)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Commission as % of Exposure')\n",
    "ax.set_title('3 ETF USD Risk Premia - Commission as pct of exposure')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio returns\n",
    "norebal_portfolioreturn = ew_norebal.groupby('date').agg({\n",
    "    'exposure': 'sum',\n",
    "    'commission': 'sum'\n",
    "}).reset_index()\n",
    "norebal_portfolioreturn.columns = ['date', 'totalequity', 'totalcommission']\n",
    "norebal_portfolioreturn = norebal_portfolioreturn.sort_values('date')\n",
    "norebal_portfolioreturn['returns'] = norebal_portfolioreturn['totalequity'].pct_change()\n",
    "\n",
    "# Performance metrics\n",
    "returns = norebal_portfolioreturn['returns'].dropna()\n",
    "annual_return = (1 + returns.mean())**12 - 1\n",
    "annual_vol = returns.std() * np.sqrt(12)\n",
    "sharpe = annual_return / annual_vol\n",
    "\n",
    "# Maximum drawdown\n",
    "cumulative = (1 + returns).cumprod()\n",
    "running_max = cumulative.expanding().max()\n",
    "drawdown = (cumulative - running_max) / running_max\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "print(\"Summary Performance Metrics:\")\n",
    "print(f\"Annualized Return: {annual_return:.2%}\")\n",
    "print(f\"Annualized Volatility: {annual_vol:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"\\nTotal Commission: ${norebal_portfolioreturn['totalcommission'].sum():.2f}\")\n",
    "print(f\"Turnover: 0 (buy and hold)\")\n",
    "\n",
    "totalprofit = norebal_portfolioreturn['totalequity'].iloc[-1] - initEq\n",
    "costprofit = norebal_portfolioreturn['totalcommission'].sum() / totalprofit\n",
    "print(f\"Total Profit: ${totalprofit:.2f}\")\n",
    "print(f\"Trading costs as % of profit: {costprofit:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 2: Equal Dollar Weight with Rebalancing\n",
    "\n",
    "Inputs for this strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initEq = 10000  # Initial equity\n",
    "perShareComm = 0.005  # Per-share commission\n",
    "minCommPerOrder = 1  # Minimum commission per order\n",
    "rebalFrequency = 1  # Rebalance frequency in months (1 to 12)\n",
    "capFrequency = 1  # Frequency to capitalise profits (0 to 12, 0 = don't capitalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rebalFrequency > 0, \"rebalFrequency must be > 0\"\n",
    "\n",
    "# Create wide dataframes for vectorized backtest\n",
    "wideprices = monthlyprices.pivot(index='date', columns='ticker', values='close')\n",
    "\n",
    "# Initialize tracking variables\n",
    "rowlist = []\n",
    "cash = initEq\n",
    "sharepos = np.array([0., 0., 0.])\n",
    "equity = initEq\n",
    "capEquity = initEq  # Sticky equity for capitalisation frequency\n",
    "\n",
    "# Iterate through prices\n",
    "for i in range(len(wideprices)):\n",
    "    currentdate = wideprices.index[i]\n",
    "    currentprice = wideprices.iloc[i].values\n",
    "    equity = np.sum(sharepos * currentprice) + cash\n",
    "    \n",
    "    # Update capEquity if it's re-capitalisation time\n",
    "    if capFrequency > 0 and i % capFrequency == 0:\n",
    "        capEquity = equity\n",
    "    \n",
    "    # Update position sizing if it's rebalance time\n",
    "    if i == 0 or i % rebalFrequency == 0:\n",
    "        targetshares = np.floor((capEquity / 3) / currentprice)\n",
    "    \n",
    "    trades = targetshares - sharepos\n",
    "    tradevalue = trades * currentprice\n",
    "    commissions = np.abs(trades) * perShareComm\n",
    "    commissions = np.where(commissions < minCommPerOrder, minCommPerOrder, commissions)\n",
    "    \n",
    "    # Adjust cash\n",
    "    cash = cash - np.sum(tradevalue) - np.sum(commissions)\n",
    "    sharepos = targetshares.copy()\n",
    "    sharevalue = sharepos * currentprice\n",
    "    equity = np.sum(sharevalue) + cash\n",
    "    \n",
    "    # Create dataframe row\n",
    "    tickers = wideprices.columns.tolist()\n",
    "    row_df = pd.DataFrame({\n",
    "        'ticker': ['cash'] + tickers,\n",
    "        'date': [currentdate] * 4,\n",
    "        'close': [0] + currentprice.tolist(),\n",
    "        'shares': [0] + sharepos.tolist(),\n",
    "        'exposure': [cash] + sharevalue.tolist(),\n",
    "        'sharetrades': [0] + trades.tolist(),\n",
    "        'tradevalue': [-np.sum(tradevalue)] + tradevalue.tolist(),\n",
    "        'commission': [0] + commissions.tolist()\n",
    "    })\n",
    "    \n",
    "    rowlist.append(row_df)\n",
    "\n",
    "# Combine into single dataframe\n",
    "ew_rebal = pd.concat(rowlist, ignore_index=True)\n",
    "\n",
    "print(f\"Equal-weight rebalancing backtest created with {len(ew_rebal)} rows\")\n",
    "ew_rebal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart\n",
    "pivot_data = ew_rebal.pivot(index='date', columns='ticker', values='exposure')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(pivot_data.index, pivot_data.T, labels=pivot_data.columns, alpha=0.8)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Exposure ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Equal Weight, Rebalancing')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Commission chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_comm = ew_rebal.pivot(index='date', columns='ticker', values='commission')\n",
    "pivot_comm.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Commission ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Commission ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trades as % of position size\n",
    "trades_pct = ew_rebal[ew_rebal['ticker'] != 'cash'].copy()\n",
    "trades_pct['tradepct'] = trades_pct['tradevalue'] / trades_pct['exposure'].replace(0, np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "tickers = sorted(trades_pct['ticker'].unique())\n",
    "width = 20\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_data = trades_pct[trades_pct['ticker'] == ticker]\n",
    "    offset = (i - len(tickers)/2) * width\n",
    "    ax.bar(ticker_data['date'] + pd.Timedelta(days=offset), \n",
    "           ticker_data['tradepct'], \n",
    "           width=width, \n",
    "           label=ticker)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Trade as % of Position')\n",
    "ax.set_title('3 ETF USD Risk Premia - Trades (as % of position size)')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio returns\n",
    "rebal_portfolioreturn = ew_rebal.groupby('date').agg({\n",
    "    'exposure': 'sum',\n",
    "    'commission': 'sum'\n",
    "}).reset_index()\n",
    "rebal_portfolioreturn.columns = ['date', 'totalequity', 'totalcommission']\n",
    "rebal_portfolioreturn = rebal_portfolioreturn.sort_values('date')\n",
    "rebal_portfolioreturn['returns'] = rebal_portfolioreturn['totalequity'].pct_change()\n",
    "\n",
    "# Performance metrics\n",
    "returns = rebal_portfolioreturn['returns'].dropna()\n",
    "annual_return = (1 + returns.mean())**12 - 1\n",
    "annual_vol = returns.std() * np.sqrt(12)\n",
    "sharpe = annual_return / annual_vol\n",
    "\n",
    "# Maximum drawdown\n",
    "cumulative = (1 + returns).cumprod()\n",
    "running_max = cumulative.expanding().max()\n",
    "drawdown = (cumulative - running_max) / running_max\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "print(\"Summary Performance Metrics:\")\n",
    "print(f\"Annualized Return: {annual_return:.2%}\")\n",
    "print(f\"Annualized Volatility: {annual_vol:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"\\nTotal Commission: ${rebal_portfolioreturn['totalcommission'].sum():.2f}\")\n",
    "\n",
    "# Calculate turnover\n",
    "totalselltrades = ew_rebal[\n",
    "    (ew_rebal['ticker'] != 'cash') & (ew_rebal['tradevalue'] < 0)\n",
    "]['tradevalue'].sum()\n",
    "meanequity = rebal_portfolioreturn['totalequity'].mean()\n",
    "num_years = (endDate.year - startDate.year)\n",
    "turnover = -totalselltrades / (meanequity * num_years) if num_years > 0 else 0\n",
    "print(f\"Annual Turnover: {turnover:.2f}\")\n",
    "\n",
    "totalprofit = rebal_portfolioreturn['totalequity'].iloc[-1] - initEq\n",
    "costprofit = rebal_portfolioreturn['totalcommission'].sum() / totalprofit\n",
    "print(f\"Total Profit: ${totalprofit:.2f}\")\n",
    "print(f\"Trading costs as % of profit: {costprofit:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 3: Simple Risk Parity\n",
    "\n",
    "Inputs for this strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initEq = 10000  # Initial equity\n",
    "perShareComm = 0.005  # Per-share commission\n",
    "minCommPerOrder = 1  # Minimum commission per order\n",
    "rebalFrequency = 1  # Rebalance frequency in months\n",
    "capFrequency = 1  # Frequency to capitalise profits\n",
    "assetVolTarget = 0.05  # Asset volatility target (0.01 to 0.1)\n",
    "volLookback = 30  # Volatility lookback period in days (5 to 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Volatility Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily volatility target sizing\n",
    "theosize_daily = prices.copy()\n",
    "theosize_daily = theosize_daily.sort_values(['ticker', 'date'])\n",
    "\n",
    "# Calculate returns\n",
    "theosize_daily['returns'] = theosize_daily.groupby('ticker')['closeadjusted'].pct_change()\n",
    "\n",
    "# Calculate rolling volatility (annualized)\n",
    "theosize_daily['vol'] = theosize_daily.groupby('ticker')['returns'].transform(\n",
    "    lambda x: x.rolling(window=volLookback, min_periods=volLookback).std() * np.sqrt(252)\n",
    ")\n",
    "\n",
    "# Calculate theoretical size (lagged)\n",
    "theosize_daily['theosize'] = (assetVolTarget / theosize_daily['vol']).shift(1)\n",
    "\n",
    "# Calculate total size and adjustment factor to constrain leverage to 1\n",
    "totalsize = theosize_daily.groupby('date')['theosize'].sum().reset_index()\n",
    "totalsize.columns = ['date', 'totalsize']\n",
    "totalsize['adjfactor'] = np.where(totalsize['totalsize'] > 1, 1 / totalsize['totalsize'], 1)\n",
    "\n",
    "# Apply constraint\n",
    "theosize_constrained = theosize_daily.merge(totalsize, on='date')\n",
    "theosize_constrained['theosize_constrained'] = (\n",
    "    theosize_constrained['theosize'] * theosize_constrained['adjfactor']\n",
    ")\n",
    "theosize_constrained = theosize_constrained[[\n",
    "    'ticker', 'date', 'closeadjusted', 'returns', 'vol', 'theosize', 'theosize_constrained'\n",
    "]].dropna()\n",
    "\n",
    "# Get month-end snapshots\n",
    "volsizeprices = monthlyprices.merge(\n",
    "    theosize_constrained[['ticker', 'date', 'theosize_constrained']], \n",
    "    on=['ticker', 'date']\n",
    ")\n",
    "\n",
    "print(f\"Calculated volatility sizing for {len(volsizeprices)} rows\")\n",
    "volsizeprices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Theoretical Constrained Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart of theoretical sizing\n",
    "pivot_sizing = volsizeprices.pivot(index='date', columns='ticker', values='theosize_constrained')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(pivot_sizing.index, pivot_sizing.T, labels=pivot_sizing.columns, alpha=0.8)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sizing (% of Portfolio)')\n",
    "plt.title('3 ETF USD Risk Premia - Theoretical Constrained Sizing')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest Volatility Targeting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rebalFrequency > 0, \"rebalFrequency must be > 0\"\n",
    "\n",
    "# Create wide dataframes\n",
    "wideprices = volsizeprices.pivot(index='date', columns='ticker', values='close')\n",
    "widetheosize = volsizeprices.pivot(index='date', columns='ticker', values='theosize_constrained')\n",
    "\n",
    "# Initialize tracking variables\n",
    "rowlist = []\n",
    "cash = initEq\n",
    "sharepos = np.array([0., 0., 0.])\n",
    "equity = initEq\n",
    "capEquity = initEq\n",
    "\n",
    "# Iterate through prices\n",
    "for i in range(len(wideprices)):\n",
    "    currentdate = wideprices.index[i]\n",
    "    currentprice = wideprices.iloc[i].values\n",
    "    currenttheosize = widetheosize.iloc[i].values\n",
    "    equity = np.sum(sharepos * currentprice) + cash\n",
    "    \n",
    "    # Update capEquity if it's re-capitalisation time\n",
    "    if capFrequency > 0 and i % capFrequency == 0:\n",
    "        capEquity = equity\n",
    "    \n",
    "    # Update position sizing if it's rebalance time\n",
    "    if i == 0 or i % rebalFrequency == 0:\n",
    "        targetshares = np.floor((capEquity * currenttheosize) / currentprice)\n",
    "    \n",
    "    trades = targetshares - sharepos\n",
    "    tradevalue = trades * currentprice\n",
    "    commissions = np.abs(trades) * perShareComm\n",
    "    commissions = np.where(commissions < minCommPerOrder, minCommPerOrder, commissions)\n",
    "    \n",
    "    # Adjust cash\n",
    "    cash = cash - np.sum(tradevalue) - np.sum(commissions)\n",
    "    sharepos = targetshares.copy()\n",
    "    sharevalue = sharepos * currentprice\n",
    "    equity = np.sum(sharevalue) + cash\n",
    "    \n",
    "    # Create dataframe row\n",
    "    tickers = wideprices.columns.tolist()\n",
    "    row_df = pd.DataFrame({\n",
    "        'ticker': ['cash'] + tickers,\n",
    "        'date': [currentdate] * 4,\n",
    "        'close': [0] + currentprice.tolist(),\n",
    "        'shares': [0] + sharepos.tolist(),\n",
    "        'exposure': [cash] + sharevalue.tolist(),\n",
    "        'sharetrades': [0] + trades.tolist(),\n",
    "        'tradevalue': [-np.sum(tradevalue)] + tradevalue.tolist(),\n",
    "        'commission': [0] + commissions.tolist()\n",
    "    })\n",
    "    \n",
    "    rowlist.append(row_df)\n",
    "\n",
    "# Combine into single dataframe\n",
    "volsize_rebal = pd.concat(rowlist, ignore_index=True)\n",
    "\n",
    "print(f\"Risk parity backtest created with {len(volsize_rebal)} rows\")\n",
    "volsize_rebal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart\n",
    "pivot_data = volsize_rebal.pivot(index='date', columns='ticker', values='exposure')\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(pivot_data.index, pivot_data.T, labels=pivot_data.columns, alpha=0.8)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Exposure ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Simple Risk Parity')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Commission chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "pivot_comm = volsize_rebal.pivot(index='date', columns='ticker', values='commission')\n",
    "pivot_comm.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Commission ($)')\n",
    "plt.title('3 ETF USD Risk Premia - Commission ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trades as % of position size\n",
    "trades_pct = volsize_rebal[volsize_rebal['ticker'] != 'cash'].copy()\n",
    "trades_pct['tradepct'] = trades_pct['tradevalue'] / trades_pct['exposure'].replace(0, np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "tickers = sorted(trades_pct['ticker'].unique())\n",
    "width = 20\n",
    "for i, ticker in enumerate(tickers):\n",
    "    ticker_data = trades_pct[trades_pct['ticker'] == ticker]\n",
    "    offset = (i - len(tickers)/2) * width\n",
    "    ax.bar(ticker_data['date'] + pd.Timedelta(days=offset), \n",
    "           ticker_data['tradepct'], \n",
    "           width=width, \n",
    "           label=ticker)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Trade as % of Position')\n",
    "ax.set_title('3 ETF USD Risk Premia - Trades (as % of position size)')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio returns\n",
    "volsize_portfolioreturn = volsize_rebal.groupby('date').agg({\n",
    "    'exposure': 'sum',\n",
    "    'commission': 'sum'\n",
    "}).reset_index()\n",
    "volsize_portfolioreturn.columns = ['date', 'totalequity', 'totalcommission']\n",
    "volsize_portfolioreturn = volsize_portfolioreturn.sort_values('date')\n",
    "volsize_portfolioreturn['returns'] = volsize_portfolioreturn['totalequity'].pct_change()\n",
    "\n",
    "# Performance metrics\n",
    "returns = volsize_portfolioreturn['returns'].dropna()\n",
    "annual_return = (1 + returns.mean())**12 - 1\n",
    "annual_vol = returns.std() * np.sqrt(12)\n",
    "sharpe = annual_return / annual_vol\n",
    "\n",
    "# Maximum drawdown\n",
    "cumulative = (1 + returns).cumprod()\n",
    "running_max = cumulative.expanding().max()\n",
    "drawdown = (cumulative - running_max) / running_max\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "print(\"Summary Performance Metrics:\")\n",
    "print(f\"Annualized Return: {annual_return:.2%}\")\n",
    "print(f\"Annualized Volatility: {annual_vol:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"\\nTotal Commission: ${volsize_portfolioreturn['totalcommission'].sum():.2f}\")\n",
    "\n",
    "# Calculate turnover\n",
    "totalselltrades = volsize_rebal[\n",
    "    (volsize_rebal['ticker'] != 'cash') & (volsize_rebal['tradevalue'] < 0)\n",
    "]['tradevalue'].sum()\n",
    "meanequity = volsize_portfolioreturn['totalequity'].mean()\n",
    "num_years = (endDate.year - startDate.year)\n",
    "turnover = -totalselltrades / (meanequity * num_years) if num_years > 0 else 0\n",
    "print(f\"Annual Turnover: {turnover:.2f}\")\n",
    "\n",
    "totalprofit = volsize_portfolioreturn['totalequity'].iloc[-1] - initEq\n",
    "costprofit = volsize_portfolioreturn['totalcommission'].sum() / totalprofit\n",
    "print(f\"Total Profit: ${totalprofit:.2f}\")\n",
    "print(f\"Trading costs as % of profit: {costprofit:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale to 10% Volatility Target\n",
    "\n",
    "Scale the portfolio returns to achieve a 10% annualized volatility based on realised volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate backtested portfolio NAV and returns\n",
    "port = volsize_rebal.groupby('date')['exposure'].sum().reset_index()\n",
    "port.columns = ['date', 'nav']\n",
    "port = port.sort_values('date')\n",
    "port['returns'] = port['nav'].pct_change()\n",
    "\n",
    "# Calculate realised volatility and scaling factor\n",
    "realised_vol = port['returns'].std() * np.sqrt(12)  # Monthly data\n",
    "vtarget = 0.1  # 10% target volatility\n",
    "scaling_factor = vtarget / realised_vol\n",
    "\n",
    "# Scale returns\n",
    "port['scaled_returns'] = port['returns'] * scaling_factor\n",
    "\n",
    "# Verify scaled volatility\n",
    "scaled_vol = port['scaled_returns'].std() * np.sqrt(12)\n",
    "print(f\"Original volatility: {realised_vol:.2%}\")\n",
    "print(f\"Scaling factor: {scaling_factor:.2f}\")\n",
    "print(f\"Scaled volatility: {scaled_vol:.2%}\")\n",
    "print(f\"Target volatility: {vtarget:.2%}\")\n",
    "\n",
    "port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Returns to Disk\n",
    "\n",
    "Save the scaled portfolio returns for use in the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "output_data = port[['date', 'scaled_returns']].dropna()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path('..') / 'portfolio' / 'data'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / 'rp_returns_volten.pkl'\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(output_data, f)\n",
    "\n",
    "print(f\"Saved scaled portfolio returns to {output_path}\")\n",
    "print(f\"\\nSaved {len(output_data)} rows of returns\")\n",
    "output_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}